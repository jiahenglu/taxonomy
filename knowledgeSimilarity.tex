\documentclass{sig-alternate}
\usepackage{txfonts}
\usepackage{ifpdf}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{multirow}
\usepackage{microtype}
\usepackage{algorithm}
\usepackage{paralist}
\usepackage[sort]{cite}
\usepackage[pdfborder={0 0 0},plainpages,pdfpagelabels=false]{hyperref}

\setlength{\paperheight}{11in}
\setlength{\paperwidth}{8.5in}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{lem}[theorem]{Lemma}
\newtheorem{terminology}[theorem]{Terminology}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{problem}[theorem]{Problem}


\newtheorem{defi}[theorem]{Definition}
\newtheorem{exa}[theorem]{Example}

% QED symbol at the end of definitions and examples
\newif\ifqedwritten
\newenvironment{definition}[1][]{\begin{defi}[#1]\upshape\qedwrittenfalse}{\qedhere\end{defi}}
\newenvironment{example}{\begin{exa}\upshape\qedwrittenfalse}{\qedhere\end{exa}}
\newcommand{\qedhere}{\ifqedwritten\else\ifmmode\tag*{\qed}\else\hfill\qed\fi\global\qedwrittentrue\fi}

\newcommand{\topk}{\mbox{top-$k$}}
\newcommand{\Topk}{\mbox{Top-$k$}}
\newcommand{\topkm}{\mbox{top-$k$,$m$}}
\newcommand{\Topkm}{\mbox{Top-$k$,$m$}}

\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}

% More tolerant setting for floats -- more compactness
\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\renewcommand{\textfloatsep}{1em}
\renewcommand{\dbltextfloatsep}{1em}

%%%%%%%%%%%%%%%  Magic for tighter spacing around theorem-like environments
\makeatletter
\def\@begintheorem#1#2{%
    \vspace{-3pt}
    \parskip -1pt
    \trivlist
    \item[%
        \hskip 10\p@
        \hskip \labelsep
        {{\sc #1}\hskip 5\p@\relax#2.}%
    ]
    \it
}
\let\old@endtheorem\@endtheorem
\def\@endtheorem{\old@endtheorem\vspace{-8pt}}
\makeatother

\begin{document}

%\conferenceinfo{SIGMOD '12,} {May 20--24, 2012, Scottsdale, Arizona, USA.}
%\CopyrightYear{2012}
%\crdata{978-1-4503-1247-9/12/05}
%\clubpenalty=10000
%\widowpenalty = 10000


\title{Exact and Approximate String Joins with Taxonomy}

%\numberofauthors{5}

\author{
%\alignauthor{Jiaheng Lu  \\
%       \affaddr{$^{\dag}$ School of Information and DEKE, MOE, Renmin
%University of China; Beijing, China}\\
%       \email{\{jiahenglu\}@ruc.edu.cn,  pierre@senellart.com}
%}
}


%For example, in XML keyword query refinement, each
%keyword is associated with a set of alternative terms.  Each term is
%associated with an inverted list containing the occurrences and the
%weights of the corresponding elements in the XML database. The
%\topkm{} queries return top-$k$ refined keyword combinations
%according to the corresponding \mbox{top-$m$} search results of keyword
%queries. In general, \topkm{} queries are useful in scenarios
%where the problem of selecting \emph{combinations
%of attributes} associated with ranked inverted lists naturally occurs.
%Applications range


\maketitle

\begin{abstract}

A string join finds all string pairs between two input string collections. It is an essential operation in
many applications, such as databases, data integration and data cleansing. This paper investigates a novel challenge to integrate taxonomy information into string joins. In general, the taxonomy presents a general-purpose strategy to improve the accuracy of string joins by enriching data with semantics-based knowledge  (i.e., a set of is-a hierarchies). For example, two records about ``Helsinki'' and ``Finland'' may have closely semantic relationship, as Helsinki is the  capital and largest city of Finland.

This work presents a solution for answering similarity join queries with taxonomy. We first study string join which specifies the exact the IS-A relationship between strings. Then we study the similarity string joins. We develop a new similarity measure with taxonomy. Then we propose new similarity join algorithms. We propose a new composite signatures. In order to optimize the processing, the key step is to decide a parameter $n$. Then we extend the count-min sketch to develop an estimation algorithm. This estimator provides strong low-error, high-confidence guarantees while requiring only logarithmic space and time costs,
thus making our method attractive both in theory and in practice. Finally, the extensive performance evaluation shows that the exact and approximate string joins utilize the taxonomy to improve the effectiveness of joins  and scales very well when important parameters like  data size, and number of dimensions increase.

\end{abstract}

%\category{H.2.4}{Database Management}{Systems}[Query processing]
%\category{H.3.3}{Database Management}{Information Search and
%Retrieval}[Search process]

%\terms{Algorithms, Experimentation, Performance, Theory}

%\keywords{keyword search, package search, top-$k$ querying}

\input{introduction}

\input{relatedwork}

\input{preliminaries}


\section{String joins with taxonomy}

We consider the exact joins including hypernymy and hyponymy and mixed three predicates based on taxonomy T.



The baseline join algorithm is the nested-loop join. All string pairs are accessed to determine the hyper-hypo relationships. But this algorithm is obviously not efficient. Therefore, we propose an efficient algorithm.



\begin{figure}[t]
\centering
\includegraphics[width=0.45\textwidth]{figures/taxonomylabels}
 \caption{An example of taxonomy with labels}
\label{fig:taxonomy}
\end{figure}



\begin{figure}[t]
\centering
\includegraphics[scale=0.4]{figures/labeljoins}
 \caption{Join inverted lists}
\label{fig:taxonomy}
\end{figure}


%\begin{algorithm}
%{\bf Input}: two strings $s_1$ and $s_2$ \\
%{\bf Output}: four relationships: R=\{Hype, Hypo, Equa and Non\}
%\begin{compactenum}[(1)]
%\item {\bf If} ($s_1 = s_2$ )  {\bf return} Equa;
%\item {\bf If} ($|LCD(s_1)| >$ 1 AND $|LCD(s_2)| >$ 1 )  {\bf return} None;
%\item {\bf Else} {\bf if} ($|LCD(s_1)| =$ 1 AND $|LCD(s_2)| >$ 1 )
%\item \verb"  " {\bf If}  $\forall t \in LCD(s_1)$, $t$ is a hypernym of $LCD(s_2)$
%\item \verb"    " {\bf return} Hype {\bf else} {\bf return} None;
%\item {\bf Else} {\bf if} ($|LCD(s_2)| =$ 1 AND $|LCD(s_1)| >$ 1 )
%\item \verb"  " {\bf If}  $\forall t \in LCD(s_2)$, $t$ is a hypernym of $LCD(s_1)$
%\item  \verb"    " {\bf return} Hypo {\bf else} {\bf return} None;
%\item {\bf Else} /\ *  $|LCD(s_1)| = |LCD(s_2)| = $ 1 */\
%\item  \verb"  " {\bf If}  $LCD(s_1)$ is a hypernym of $LCD(s_2)$  {\bf return} Hype
%\item   \verb"  " {\bf Else if}  $LCD(s_1)$ is a hyponym of $LCD(s_2)$  {\bf return} Hypo
%\item   \verb"  " {\bf Else return} none
%\end{compactenum}
%\caption{Determine the relationship between two strings}
%\label{alg:measure}
%\end{algorithm}


\begin{algorithm}
{\bf Input}: two sets of strings $S_1$ and $S_2$, a taxonomy $T$ \\
{\bf Output}: string pairs $(s_1,s_2) \in S_1 \times S_2$ s.t. $s_1 \sqsubset s_2$ or $s_2 \sqsubset s_1$
\begin{compactenum}[(1)]
\item Let $G_s$ and $G_t$ denote the inverted lists for S and T respectively.
\item Perform a join operation to find the IS-A relationship between $G_s$ and $G_t$
\item {\bf FOR} EACH join pair ($t_1,t_2$)
\item  $R = R \cup t_1.List \times t_2.List$
\item $R$
\end{compactenum}
\caption{String joins with taxonomy}
\label{alg:exactjoin}
\end{algorithm}

Note that the above algorithm may contain the duplicate result set. Therefore, we need to sort and remove the duplication.

\begin{theorem}  Algorithm \ref{alg:exactjoin} is an optimal algorithm. The computing cost is linear to the sum of the size of the input and output. That is, each output result contribute to the final answer.
\end{theorem}

\subsection{Join algorithms}

The key to an efficient, uniform mechanism for set-at-atime
(join-based) matching of query graph patterns is a positional
representation of occurrences of  elements and in the taxonomy database (see, e.g., [6, 7, 27]),
which extends the classic inverted index data structure in information retrieval [22]. We borrow the labeling scheme from XML databases and use the prefix based labels. Structural relationships between tree nodes whose positions
are recorded in this fashion can be determined easily for hypernym or hyponym relationships.

There are two kinds of edges in a graph pattern, ``$\rightarrow$'' and ``$\leftarrow$''shows the IS-A relationship, hypernym and hyponym and ``$\leftrightarrows$'' is a mixedISA relationship.

In general, at each node in the query graph pattern, there is
a node predicate on the attributes (e.g., tag, content) of the
node in question. For the purposes of this paper, exactly
what is permitted in this predicate is not material.  It suffices
for our purposes that there be efficient access mechanisms
(such as index structures) to identify the nodes in the
database that satisfy any given node predicate $q$, and
return a stream of matches $T_q$ based on the taxonomy.

\input{similarityjoins}


\section{Experimental analysis}

To evaluate the effectiveness of the proposed top-$k$ completion
techniques, Expansion Trie (ET), Two tries (TT), and  Realizer Trie (RT), we will compare
their effectiveness on the following datasets from different
application scenarios in Java $1.6.0$ and run on a
Windows XP with dual-core Intel Xeon CPU 4.0GHz, 2GB RAM, and a 320GB hard disk.


\subsection{Datasets}
We use three datasets: US addresses (\textbf{USPS}),
conference titles  (\textbf{CONF}), and gene/protein data
(\textbf{SPROT}). These datasets differ from each other in terms of rule-number, rule-complexity, data-size and string-length. Our goal in choosing these diverse sources is to understand the usefulness of algorithms in different real world environments.

\smallskip
\noindent \textbf{{USPS}}: We downloaded common person names, street names,
city names, states, and zip codes from the United States Postal
Service website ({\footnotesize http://www.usps.com}). We then generated
one million records, each of which contains a person name, a street
name, a city name, a state, and a zip code. USPS also publishes
extensive information about the format of US addresses, from which we
obtained 284 synonym pairs. The synonym pairs covers a wide range of alternate
representations of common strings, e.g. street $\rightarrow$ st.


\noindent \textbf{{CONF}}: We collected 10,000 conference names
from more than ten domains, including Medicine and Computer
Science.
We obtained $1000$ synonym pairs between the full names of conferences and their
abbreviations by manually examining conference websites or homepages
of scientists.


\noindent \textbf{{SPROT}}: We obtained one million gene/protein records
from the Expasy website ({\footnotesize http://www.expasy.ch/sprot}).
Each record contains an identifier (ID) and its name.
%For example, the two records, \textit{(O00203, Adapter-related protein complex 3
%beta-1 subunit)} and \textit{(O00203, AP-3 complex subunit
%beta-1)}, refer to the same gene as they have the same ID.
In this dataset, each ID has $5\sim22$ synonyms. We generated 10,000 synonym rules describing gene/protein
equivalent expressions.

In each dataset we subtracted from the scores their minimum,
so that the smallest score is 0, without affecting the
ordering. The minimum is then added back at query time.




\begin{figure}
  \small
  \centering
  \includegraphics[width=\linewidth]{figures/Characteristics_Datasets}
   \vspace{-6mm}
  \caption{Characteristics of Datasets.}
  \label{tab:data_characteristics}
\end{figure}


Figure~\ref{tab:data_characteristics} gives the characteristics of the
three datasets.




%***************************************Conclusion and future work************************************
\section{Conclusion and future work}

We introduce a new query type, approximate string join, with taxonomy. We propose processing
models for taxonomy queries, and introduce how to build
an additional index (besides the inverted index) to support
efficient query processing. In particular, we study the problem
of how to optimize this additional index based on a
workload of queries, with the goal of minimizing query processing
cost, and propose algorithms with performance guarantees.
Our index optimization techniques are tested using
real datasets and are shown to be effective and robust.



\bibliographystyle{abbrv}
\bibliography{localrefs}



\end{document}
